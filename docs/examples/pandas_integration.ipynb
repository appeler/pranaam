{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pandas Integration Examples\n",
    "\n",
    "This notebook demonstrates how to use pranaam with pandas DataFrames for real-world data processing and analysis.\n",
    "\n",
    "We'll cover:\n",
    "1. Basic DataFrame processing\n",
    "2. Data analysis with predictions\n",
    "3. Confidence-based filtering\n",
    "4. Saving and exporting results\n",
    "\n",
    "Let's start by importing our dependencies:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "import pranaam\n",
    "\n",
    "print(f\"Pandas version: {pd.__version__}\")\n",
    "print(f\"Pranaam version: {pranaam.__version__ if hasattr(pranaam, '__version__') else 'latest'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating Sample Data\n",
    "\n",
    "First, let's create a sample employee dataset to work with:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_sample_data():\n",
    "    \"\"\"Create sample employee data for demonstration.\"\"\"\n",
    "    return pd.DataFrame({\n",
    "        \"employee_id\": [1001, 1002, 1003, 1004, 1005, 1006],\n",
    "        \"name\": [\n",
    "            \"Shah Rukh Khan\",\n",
    "            \"Priya Sharma\",\n",
    "            \"Mohammed Ali\",\n",
    "            \"Raj Patel\",\n",
    "            \"Fatima Khan\",\n",
    "            \"Amitabh Bachchan\",\n",
    "        ],\n",
    "        \"department\": [\n",
    "            \"Engineering\",\n",
    "            \"Marketing\",\n",
    "            \"Finance\",\n",
    "            \"HR\",\n",
    "            \"Engineering\",\n",
    "            \"Management\",\n",
    "        ],\n",
    "        \"salary\": [75000, 65000, 70000, 60000, 80000, 120000],\n",
    "    })\n",
    "\n",
    "# Create our sample data\n",
    "df = create_sample_data()\n",
    "print(\"Original employee data:\")\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìä Basic DataFrame Processing\n",
    "\n",
    "Now let's add religion predictions to our DataFrame using pranaam:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get predictions for the name column\n",
    "print(\"Getting predictions for all names...\")\n",
    "predictions = pranaam.pred_rel(df[\"name\"], lang=\"eng\")\n",
    "print(\"\\nPredictions:\")\n",
    "print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge predictions back to original DataFrame\n",
    "# Note: pranaam returns name, pred_label, pred_prob_muslim\n",
    "df_with_predictions = df.merge(\n",
    "    predictions[[\"name\", \"pred_label\", \"pred_prob_muslim\"]],\n",
    "    on=\"name\",\n",
    "    how=\"left\"\n",
    ")\n",
    "\n",
    "print(\"Combined data with predictions:\")\n",
    "print(df_with_predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìà Data Analysis with Predictions\n",
    "\n",
    "Now let's perform some analysis using the religion predictions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic statistics\n",
    "print(\"Religion distribution in our dataset:\")\n",
    "religion_counts = df_with_predictions[\"pred_label\"].value_counts()\n",
    "print(religion_counts)\n",
    "print(\"\\nPercentage breakdown:\")\n",
    "print(religion_counts / len(df_with_predictions) * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Average salary by predicted religion\n",
    "print(\"Salary analysis by predicted religion:\")\n",
    "salary_by_religion = df_with_predictions.groupby(\"pred_label\")[\"salary\"].agg([\n",
    "    'mean', 'median', 'min', 'max', 'count'\n",
    "])\n",
    "print(salary_by_religion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Department distribution by predicted religion\n",
    "print(\"Department vs Religion cross-tabulation:\")\n",
    "dept_religion = pd.crosstab(\n",
    "    df_with_predictions[\"department\"],\n",
    "    df_with_predictions[\"pred_label\"],\n",
    "    margins=True\n",
    ")\n",
    "print(dept_religion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üéØ Confidence-Based Analysis\n",
    "\n",
    "Not all predictions are equally certain. Let's analyze the confidence levels and filter based on them:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add confidence score calculation\n",
    "# Higher numbers mean more confident predictions\n",
    "df_with_predictions['confidence'] = df_with_predictions['pred_prob_muslim'].apply(\n",
    "    lambda x: max(x, 100 - x)\n",
    ")\n",
    "\n",
    "# Show confidence distribution\n",
    "print(\"Detailed prediction analysis:\")\n",
    "print(\"=\" * 70)\n",
    "print(f\"{'Name':<18} | {'Prediction':<10} | {'Muslim %':<8} | {'Confidence':<10}\")\n",
    "print(\"-\" * 70)\n",
    "\n",
    "for _, row in df_with_predictions.iterrows():\n",
    "    print(f\"{row['name']:<18} | {row['pred_label']:<10} | {row['pred_prob_muslim']:>6.1f}% | {row['confidence']:>8.1f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter high-confidence predictions (>90%)\n",
    "high_confidence_mask = df_with_predictions['confidence'] > 90\n",
    "high_confidence_df = df_with_predictions[high_confidence_mask]\n",
    "\n",
    "print(\"High-confidence predictions (confidence > 90%):\")\n",
    "print(f\"Found {len(high_confidence_df)} out of {len(df_with_predictions)} predictions\")\n",
    "print(\"\\nHigh-confidence results:\")\n",
    "print(high_confidence_df[['name', 'pred_label', 'pred_prob_muslim', 'confidence']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confidence level categorization\n",
    "df_with_predictions['confidence_level'] = pd.cut(\n",
    "    df_with_predictions['confidence'],\n",
    "    bins=[0, 70, 85, 95, 100],\n",
    "    labels=['Low', 'Medium', 'High', 'Very High'],\n",
    "    include_lowest=True\n",
    ")\n",
    "\n",
    "print(\"Confidence level distribution:\")\n",
    "conf_dist = df_with_predictions['confidence_level'].value_counts().sort_index()\n",
    "print(conf_dist)\n",
    "print(\"\\nPercentage:\")\n",
    "print(conf_dist / len(df_with_predictions) * 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üíæ Saving and Exporting Results\n",
    "\n",
    "Let's save our enriched dataset to various formats:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare final dataset with clean column names\n",
    "final_df = df_with_predictions[[\n",
    "    'employee_id', 'name', 'department', 'salary',\n",
    "    'pred_label', 'pred_prob_muslim', 'confidence', 'confidence_level'\n",
    "]].rename(columns={\n",
    "    'pred_label': 'predicted_religion',\n",
    "    'pred_prob_muslim': 'muslim_probability',\n",
    "    'confidence': 'prediction_confidence'\n",
    "})\n",
    "\n",
    "print(\"Final dataset with clean column names:\")\n",
    "print(final_df)\n",
    "print(f\"\\nDataset shape: {final_df.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save to CSV (most common format)\n",
    "output_file = \"employee_predictions.csv\"\n",
    "final_df.to_csv(output_file, index=False)\n",
    "print(f\"‚úÖ Results saved to {output_file}\")\n",
    "\n",
    "# Show what was saved\n",
    "print(\"\\nSaved data preview:\")\n",
    "saved_df = pd.read_csv(output_file)\n",
    "print(saved_df.head())\n",
    "print(\"\\nFile info:\")\n",
    "print(f\"- Rows: {len(saved_df)}\")\n",
    "print(f\"- Columns: {list(saved_df.columns)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean up the demo file\n",
    "import os\n",
    "\n",
    "if os.path.exists(output_file):\n",
    "    os.remove(output_file)\n",
    "    print(f\"üßπ Demo file {output_file} removed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üîç Advanced Analytics Example\n",
    "\n",
    "Let's create a summary report of our analysis:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a comprehensive summary\n",
    "print(\"üìä EMPLOYEE RELIGION PREDICTION ANALYSIS REPORT\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Dataset overview\n",
    "total_employees = len(final_df)\n",
    "print(\"\\nüìã Dataset Overview:\")\n",
    "print(f\"   Total employees analyzed: {total_employees}\")\n",
    "print(f\"   Departments: {final_df['department'].nunique()} ({', '.join(final_df['department'].unique())})\")\n",
    "print(f\"   Salary range: ${final_df['salary'].min():,} - ${final_df['salary'].max():,}\")\n",
    "\n",
    "# Religion predictions\n",
    "religion_summary = final_df['predicted_religion'].value_counts()\n",
    "print(\"\\nüîÆ Religion Predictions:\")\n",
    "for religion, count in religion_summary.items():\n",
    "    pct = count / total_employees * 100\n",
    "    print(f\"   {religion.title()}: {count} employees ({pct:.1f}%)\")\n",
    "\n",
    "# Confidence analysis\n",
    "avg_confidence = final_df['prediction_confidence'].mean()\n",
    "high_conf_count = (final_df['prediction_confidence'] > 90).sum()\n",
    "print(\"\\nüìà Confidence Analysis:\")\n",
    "print(f\"   Average confidence: {avg_confidence:.1f}%\")\n",
    "print(f\"   High confidence predictions (>90%): {high_conf_count}/{total_employees} ({high_conf_count/total_employees*100:.1f}%)\")\n",
    "\n",
    "# Department insights\n",
    "dept_analysis = final_df.groupby('department').agg({\n",
    "    'predicted_religion': lambda x: x.value_counts().index[0],  # most common religion\n",
    "    'prediction_confidence': 'mean',\n",
    "    'salary': 'mean'\n",
    "})\n",
    "print(\"\\nüè¢ Department Analysis:\")\n",
    "for dept in dept_analysis.index:\n",
    "    most_common = dept_analysis.loc[dept, 'predicted_religion']\n",
    "    avg_conf = dept_analysis.loc[dept, 'prediction_confidence']\n",
    "    avg_sal = dept_analysis.loc[dept, 'salary']\n",
    "    print(f\"   {dept}: Mostly {most_common} (avg confidence: {avg_conf:.1f}%, avg salary: ${avg_sal:,.0f})\")\n",
    "\n",
    "print(\"\\n‚úÖ Analysis complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Key Takeaways\n",
    "\n",
    "üêº **Pandas Integration**: Pranaam works seamlessly with pandas DataFrames and Series  \n",
    "üîó **Easy Merging**: Use `.merge()` to combine predictions with existing data  \n",
    "üìä **Rich Analytics**: Leverage pandas' groupby, crosstab, and aggregation functions  \n",
    "üéØ **Confidence Filtering**: Use confidence scores to filter reliable predictions  \n",
    "üíæ **Export Ready**: Save enriched datasets to CSV, Excel, or other formats  \n",
    "üìà **Business Insights**: Transform name data into actionable demographic insights  \n",
    "\n",
    "## Next Steps\n",
    "\n",
    "- **[CSV Processing](csv_processing.ipynb)**: Learn to process large CSV files\n",
    "- **[Performance Benchmarks](performance_benchmarks.ipynb)**: Optimize for large datasets\n",
    "- **[Basic Usage](basic_usage.ipynb)**: Review fundamental concepts\n",
    "\n",
    "## Best Practices\n",
    "\n",
    "1. **Always check confidence scores** - Don't trust all predictions equally\n",
    "2. **Use batch processing** - Process multiple names at once for efficiency\n",
    "3. **Handle missing data** - Check for NaN values in name columns before processing\n",
    "4. **Validate results** - Spot-check predictions against domain knowledge\n",
    "5. **Document assumptions** - Note the model's limitations and biases in your analysis"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}